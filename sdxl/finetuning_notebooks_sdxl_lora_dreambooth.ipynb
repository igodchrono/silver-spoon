{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igodchrono/silver-spoon/blob/main/sdxl/finetuning_notebooks_sdxl_lora_dreambooth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "ðŸ“Œ **This notebook has been updated in [jhj0517/finetuning-notebooks](https://github.com/jhj0517/finetuning-notebooks) repository!**\n",
        "\n",
        "## Version : 1.0.0\n",
        "---"
      ],
      "metadata": {
        "id": "doKhBBXIfS21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #(Optional) Check GPU\n",
        "\n",
        "#@markdown To train SDXL lora at least 12GB VRAM is recommended.\n",
        "#@markdown <br> And you need at least 16GB for CPU RAM, which is unfortunately not available on the free tier in Colab.\n",
        "#@markdown <br>You can check your GPU setup before start.\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "23yZvUlagEsx",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1da3bcd-28a4-457b-b7e6-2f9023eb89b3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Aug 29 14:18:11 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kNbSbsctxahq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e827c0c-4a30-44f2-c5a4-9326bd846184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 102993, done.\u001b[K\n",
            "remote: Counting objects: 100% (642/642), done.\u001b[K\n",
            "remote: Compressing objects: 100% (341/341), done.\u001b[K\n",
            "remote: Total 102993 (delta 522), reused 301 (delta 301), pack-reused 102351 (from 4)\u001b[K\n",
            "Receiving objects: 100% (102993/102993), 77.46 MiB | 16.15 MiB/s, done.\n",
            "Resolving deltas: 100% (75907/75907), done.\n",
            "/content/diffusers\n",
            "Obtaining file:///content/diffusers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers==0.36.0.dev0) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers==0.36.0.dev0) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.36.0.dev0) (0.34.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers==0.36.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.36.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers==0.36.0.dev0) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.36.0.dev0) (0.6.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers==0.36.0.dev0) (11.3.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.0->diffusers==0.36.0.dev0) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.0->diffusers==0.36.0.dev0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.0->diffusers==0.36.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.0->diffusers==0.36.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.0->diffusers==0.36.0.dev0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.0->diffusers==0.36.0.dev0) (1.1.8)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers==0.36.0.dev0) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.36.0.dev0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.36.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.36.0.dev0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.36.0.dev0) (2025.8.3)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building editable for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.36.0.dev0-0.editable-py3-none-any.whl size=11331 sha256=e2eb087f0459b6323766adaa52be712718dc73e141d1bfa69a8be542a67d610a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k1jbphjo/wheels/8a/fc/09/385efb77b455b2fd4a656c950079c93147e1f50ae614e51beb\n",
            "Successfully built diffusers\n",
            "Installing collected packages: diffusers\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.35.1\n",
            "    Uninstalling diffusers-0.35.1:\n",
            "      Successfully uninstalled diffusers-0.35.1\n",
            "Successfully installed diffusers-0.36.0.dev0\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy) (0.2.13)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy\n",
            "Successfully installed ftfy-6.3.1\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.47.0\n"
          ]
        }
      ],
      "source": [
        "#@title #1. Install Dependencies\n",
        "#@markdown This notebook is powered by https://github.com/huggingface/diffusers\n",
        "!git clone https://github.com/huggingface/diffusers\n",
        "%cd diffusers\n",
        "!pip install -e .\n",
        "\n",
        "# Cherry picked dependencies from https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/requirements_sdxl.txt to use in Colab.\n",
        "!pip install ftfy\n",
        "!pip install datasets\n",
        "!pip install bitsandbytes\n",
        "# Only install this if you want to use optimization with xformers.\n",
        "# !pip install xformers\n",
        "\n",
        "\n",
        "# Comment on the requirements above, and uncomment below if you're not using Colab.\n",
        "# !pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126\n",
        "# !pip install deepspeed\n",
        "# !pip install accelerate>=0.22.0\n",
        "# !pip install transformers>=4.25.1\n",
        "# !pip install ftfy\n",
        "# !pip install tensorboard\n",
        "# !pip install Jinja2\n",
        "# !pip install datasets\n",
        "# !pip install peft==0.7.0\n",
        "# !pip install xformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 2. (Optional) Mount Google Drive\n",
        "\n",
        "#@markdown It's not mandatory but it's recommended to mount to Google Drive and use the Google Drive's path for your training image dataset.\n",
        "\n",
        "#@markdown The dataset should have following structure:\n",
        "\n",
        "#@markdown This notebook uses diffuser's dreambooth LoRA training, you only need image files in the dataset with this way.\n",
        "\n",
        "#@markdown ### Example File Structure (Image Files Only):\n",
        "#@markdown ```\n",
        "#@markdown your-dataset/\n",
        "#@markdown â”œâ”€â”€ a (1).png         # Image file\n",
        "#@markdown â”œâ”€â”€ a (2).png         # Another image file\n",
        "#@markdown â”œâ”€â”€ a (3).png         # Another image file\n",
        "#@markdown ```\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M1bu3MpsACOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "193ea65f-bb21-4562-df8d-311423c93dcd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bMgsJrENC0-",
        "outputId": "70c8ab2e-c974-4a63-ace2-3884194980cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 3. (Optional) Register Huggingface Token To Download Base Model\n",
        "\n",
        "#@markdown If you don't have entire base model files ([stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/tree/main)) in the drive you need to sign in to Huggingface to download the model.\n",
        "\n",
        "#@markdown Get your tokens from https://huggingface.co/settings/tokens, and register it in colab's seceret as **`HF_TOKEN`** and use it in any notebook. ( 'Read' permission is enough )\n",
        "\n",
        "#@markdown To register secrets in colab, click on the key-shaped icon in the left panel and enter your **`HF_TOKEN`** like this:\n",
        "\n",
        "#@markdown ![image](https://media.githubusercontent.com/media/jhj0517/finetuning-notebooks/master/docs/screenshots/colab_secrets.png)\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "os.environ['HF_TOKEN'] = hf_token\n",
        "\n",
        "print(\"HF_TOKEN environment variable has been set.\")"
      ],
      "metadata": {
        "id": "9WzQRwZij5jf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900c2f41-f2df-47f7-85ef-237b435cede2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HF_TOKEN environment variable has been set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 4. Train with Parameters\n",
        "import os\n",
        "import toml\n",
        "import json\n",
        "import re\n",
        "\n",
        "#@markdown ## Paths Configuration\n",
        "DATASET_DIR = \"/content/drive/MyDrive/katj\" # @param {type:\"string\"}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/finetuning-notebooks/sdxl/outputs\" # @param {type:\"string\"}\n",
        "OUTPUT_NAME = \"My-SDXL-LoRA-V1\" # @param {type:\"string\"}\n",
        "\n",
        "OUTPUT_DIR = os.path.join(OUTPUT_DIR, OUTPUT_NAME)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "#@markdown ## Base Model Configuration\n",
        "BASE_MODEL_PATH_OR_ID = \"stabilityai/stable-diffusion-xl-base-1.0\" # @param {type:\"string\"}\n",
        "BASE_VAE_PATH_OR_ID = \"madebyollin/sdxl-vae-fp16-fix\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Dataset Configuration\n",
        "# CAPTION_EXTENSION = \".txt\" # @param {type:\"string\"}\n",
        "RESOLUTION = 1024 # @param {type:\"integer\"}\n",
        "# CAPTION_COLUMN = \"text\"\n",
        "\n",
        "#@markdown ## Training Settings\n",
        "MIXED_PRECISION = \"bf16\" # @param [\"no\", \"fp16\", \"bf16\"]\n",
        "INSTANCE_PROMPT = \"xxxkatj\" # @param {type:\"string\"}\n",
        "RANDOM_FLIP = True # @param {type:\"boolean\"}\n",
        "TRAIN_BATCH_SIZE = 1 # @param {type:\"integer\"}\n",
        "MAX_TRAIN_STEPS = 500 # @param {type:\"integer\"}\n",
        "CHECKPOINTING_STEPS = 1 # @param {type:\"integer\"}\n",
        "LEARNING_RATE = 1e-4 # @param {type:\"number\"}\n",
        "LR_SCHEDULER = \"constant\" # @param [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"]\n",
        "LR_WARMUP_STEPS = 0 # @param {type:\"integer\"}\n",
        "GRADIENT_ACCUMULATION_STEPS = 4 # @param {type:\"integer\"}\n",
        "SEED = 77 # @param {type:\"integer\"}\n",
        "GRADIENT_CHECKPOINTING = True # @param {type:\"boolean\"}\n",
        "USE_8_BIT_ADAM = True # @param {type:\"boolean\"}\n",
        "# ENABLE_XFORMERS_MEMORY_EFFICIENT_ATTENTION = False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown ## Network Settings\n",
        "RANK = 4 # @param {type:\"integer\"}\n",
        "\n",
        "\n",
        "#@markdown ## Validation Configuration\n",
        "#@markdown WandB is a 3rd party service, to use it you need to get an API key from https://wandb.ai/authorize.\n",
        "ENABLE_WANDB = False # @param {type:\"boolean\"}\n",
        "VALIDATION_PROMPT = \"xxxkatj\"  # @param {type:\"string\"}\n",
        "# NUM_VALIDATION_IMAGES = 4 # @param {type:\"integer\"}\n",
        "VALIDATION_EPOCHS = 25 # @param {type:\"integer\"}\n",
        "\n",
        "# Write Command\n",
        "command_parts = [\n",
        "    \"accelerate\", \"launch\",\n",
        "    \"\\\"/content/diffusers/examples/dreambooth/train_dreambooth_lora_sdxl.py\\\"\",\n",
        "]\n",
        "\n",
        "command_parts.extend([\n",
        "    f\"--pretrained_model_name_or_path=\\\"{BASE_MODEL_PATH_OR_ID}\\\"\",\n",
        "    f\"--pretrained_vae_model_name_or_path=\\\"{BASE_VAE_PATH_OR_ID}\\\"\",\n",
        "    f\"--instance_data_dir=\\\"{DATASET_DIR}\\\"\",\n",
        "    f\"--instance_prompt=\\\"{INSTANCE_PROMPT}\\\"\",\n",
        "#    f\"--caption_column={CAPTION_COLUMN}\",\n",
        "    f\"--mixed_precision={MIXED_PRECISION}\",\n",
        "    f\"--resolution={RESOLUTION}\",\n",
        "    f\"--max_train_steps={MAX_TRAIN_STEPS}\",\n",
        "    f\"--train_batch_size={TRAIN_BATCH_SIZE}\",\n",
        "    f\"--checkpointing_steps={CHECKPOINTING_STEPS}\",\n",
        "    f\"--learning_rate={LEARNING_RATE}\",\n",
        "    f\"--lr_scheduler={LR_SCHEDULER}\",\n",
        "    f\"--lr_warmup_steps={LR_WARMUP_STEPS}\",\n",
        "    f\"--seed={SEED}\",\n",
        "    f\"--output_dir={OUTPUT_DIR}\",\n",
        "    f\"--validation_prompt=\\\"{VALIDATION_PROMPT}\\\"\",\n",
        "#    f\"--num_validation_images={NUM_VALIDATION_IMAGES}\",\n",
        "    f\"--validation_epochs={VALIDATION_EPOCHS}\",\n",
        "    f\"--gradient_accumulation_steps={GRADIENT_ACCUMULATION_STEPS}\",\n",
        "    f\"--rank={RANK}\",\n",
        "\n",
        "])\n",
        "\n",
        "if RANDOM_FLIP:\n",
        "    command_parts.append(\"--random_flip\")\n",
        "\n",
        "if ENABLE_WANDB:\n",
        "    command_parts.append(\"--report_to=\\\"wandb\\\"\")\n",
        "\n",
        "if GRADIENT_CHECKPOINTING:\n",
        "    command_parts.append(\"--gradient_checkpointing\")\n",
        "\n",
        "if USE_8_BIT_ADAM:\n",
        "    command_parts.append(\"--use_8bit_adam\")\n",
        "\n",
        "# if ENABLE_XFORMERS_MEMORY_EFFICIENT_ATTENTION:\n",
        "#     command_parts.append(\"--enable_xformers_memory_efficient_attention\")\n",
        "\n",
        "# Write metadata.jsonl for the dataset\n",
        "def create_metadata_jsonl(dataset_dir, caption_extension=\".txt\"):\n",
        "    metadata = []\n",
        "    image_files = [f for f in os.listdir(dataset_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    for image_file in image_files:\n",
        "        base_name = os.path.splitext(image_file)[0]\n",
        "        caption_file = f\"{base_name}{caption_extension}\"\n",
        "\n",
        "        if os.path.exists(os.path.join(dataset_dir, caption_file)):\n",
        "            try:\n",
        "                with open(os.path.join(dataset_dir, caption_file), \"r\", encoding=\"utf-8\") as f:\n",
        "                    caption = f.read().strip()\n",
        "\n",
        "                match = re.search(r\"\\((\\d+)\\)\", base_name)\n",
        "                if match:\n",
        "                    file_number = int(match.group(1))\n",
        "                    new_file_name = f\"{file_number:04d}.png\"\n",
        "                else:\n",
        "                    file_number = len(metadata) + 1\n",
        "                    new_file_name = f\"{file_number:04d}.png\"\n",
        "\n",
        "                metadata.append({\"file_name\": new_file_name, \"text\": caption})\n",
        "\n",
        "                os.rename(os.path.join(dataset_dir, image_file), os.path.join(dataset_dir, new_file_name))\n",
        "                os.rename(os.path.join(dataset_dir, caption_file), os.path.join(dataset_dir, f\"{file_number:04d}{caption_extension}\"))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {image_file}: {e}\")\n",
        "        else:\n",
        "            print(f\"Warning: Caption file {caption_file} not found for {image_file}\")\n",
        "\n",
        "    metadata_path = os.path.join(dataset_dir, \"metadata.jsonl\")\n",
        "    with open(metadata_path, \"w\", encoding=\"utf-8\") as outfile:\n",
        "        for item in metadata:\n",
        "            json.dump(item, outfile, ensure_ascii=False)\n",
        "            outfile.write(\"\\n\")\n",
        "\n",
        "# Diffuser's script does not use each caption with dreambooth.\n",
        "# create_metadata_jsonl(DATASET_DIR, CAPTION_EXTENSION)\n",
        "# print(f\"{os.path.join(DATASET_DIR, 'metadata.jsonl')} has written.\")\n",
        "\n",
        "# Train\n",
        "!accelerate config default\n",
        "command = \" \".join(command_parts)\n",
        "print(command)\n",
        "!{command}"
      ],
      "metadata": {
        "id": "fob2cRMQeW5C",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1384c448-5fe2-4078-9450-65936f3c72b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n",
            "accelerate launch \"/content/diffusers/examples/dreambooth/train_dreambooth_lora_sdxl.py\" --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\" --instance_data_dir=\"/content/drive/MyDrive/katj\" --instance_prompt=\"xxxkatj\" --mixed_precision=bf16 --resolution=1024 --max_train_steps=500 --train_batch_size=1 --checkpointing_steps=1 --learning_rate=0.0001 --lr_scheduler=constant --lr_warmup_steps=0 --seed=77 --output_dir=/content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1 --validation_prompt=\"xxxkatj\" --validation_epochs=25 --gradient_accumulation_steps=4 --rank=4 --random_flip --gradient_checkpointing --use_8bit_adam\n",
            "2025-08-29 14:26:26.503815: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756477586.522678    6629 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756477586.529185    6629 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756477586.545340    6629 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756477586.545383    6629 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756477586.545388    6629 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756477586.545392    6629 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-29 14:26:26.550403: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "tokenizer_config.json: 100% 737/737 [00:00<00:00, 5.14MB/s]\n",
            "vocab.json: 1.06MB [00:00, 71.7MB/s]\n",
            "merges.txt: 525kB [00:00, 95.5MB/s]\n",
            "special_tokens_map.json: 100% 472/472 [00:00<00:00, 3.79MB/s]\n",
            "tokenizer_config.json: 100% 725/725 [00:00<00:00, 7.42MB/s]\n",
            "special_tokens_map.json: 100% 460/460 [00:00<00:00, 2.96MB/s]\n",
            "config.json: 100% 565/565 [00:00<00:00, 4.06MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "config.json: 100% 575/575 [00:00<00:00, 4.34MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "model_index.json: 100% 609/609 [00:00<00:00, 4.99MB/s]\n",
            "scheduler_config.json: 100% 479/479 [00:00<00:00, 5.29MB/s]\n",
            "{'dynamic_thresholding_ratio', 'rescale_betas_zero_snr', 'clip_sample_range', 'thresholding', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "text_encoder/model.safetensors: 100% 492M/492M [00:06<00:00, 70.4MB/s]\n",
            "text_encoder_2/model.safetensors: 100% 2.78G/2.78G [00:58<00:00, 47.8MB/s]\n",
            "config.json: 100% 631/631 [00:00<00:00, 4.76MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 335M/335M [00:02<00:00, 115MB/s]\n",
            "{'use_post_quant_conv', 'latents_mean', 'shift_factor', 'latents_std', 'mid_block_add_attention', 'use_quant_conv'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing AutoencoderKL.\n",
            "\n",
            "All the weights of AutoencoderKL were initialized from the model checkpoint at madebyollin/sdxl-vae-fp16-fix.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n",
            "config.json: 1.68kB [00:00, 8.13MB/s]\n",
            "unet/diffusion_pytorch_model.safetensors: 100% 10.3G/10.3G [03:30<00:00, 48.8MB/s]\n",
            "{'attention_type', 'dropout', 'reverse_transformer_layers_per_block'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing UNet2DConditionModel.\n",
            "\n",
            "All the weights of UNet2DConditionModel were initialized from the model checkpoint at stabilityai/stable-diffusion-xl-base-1.0.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.\n",
            "Steps:   0% 1/500 [00:41<5:48:54, 41.95s/it, loss=0.315, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-1/pytorch_lora_weights.safetensors\n",
            "Steps:   0% 2/500 [01:25<5:56:59, 43.01s/it, loss=0.275, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-2/pytorch_lora_weights.safetensors\n",
            "Steps:   1% 3/500 [02:09<5:57:50, 43.20s/it, loss=0.133, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-3/pytorch_lora_weights.safetensors\n",
            "Steps:   1% 4/500 [02:52<5:57:42, 43.27s/it, loss=0.0924, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-4/pytorch_lora_weights.safetensors\n",
            "Steps:   1% 5/500 [03:35<5:57:22, 43.32s/it, loss=0.316, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-5/pytorch_lora_weights.safetensors\n",
            "Steps:   1% 6/500 [04:19<5:56:54, 43.35s/it, loss=0.09, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-6/pytorch_lora_weights.safetensors\n",
            "Steps:   1% 7/500 [05:02<5:56:44, 43.42s/it, loss=0.00308, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-7/pytorch_lora_weights.safetensors\n",
            "Steps:   2% 8/500 [05:46<5:56:23, 43.46s/it, loss=0.0412, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-8/pytorch_lora_weights.safetensors\n",
            "Steps:   2% 9/500 [06:29<5:55:33, 43.45s/it, loss=0.0372, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-9/pytorch_lora_weights.safetensors\n",
            "Steps:   2% 10/500 [07:13<5:54:55, 43.46s/it, loss=0.075, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-10/pytorch_lora_weights.safetensors\n",
            "Steps:   2% 11/500 [07:56<5:54:16, 43.47s/it, loss=0.309, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-11/pytorch_lora_weights.safetensors\n",
            "Steps:   2% 12/500 [08:40<5:53:22, 43.45s/it, loss=0.126, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-12/pytorch_lora_weights.safetensors\n",
            "Steps:   3% 13/500 [09:23<5:52:53, 43.48s/it, loss=0.0531, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-13/pytorch_lora_weights.safetensors\n",
            "Steps:   3% 14/500 [10:07<5:52:18, 43.50s/it, loss=0.054, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-14/pytorch_lora_weights.safetensors\n",
            "Steps:   3% 15/500 [10:50<5:51:23, 43.47s/it, loss=0.00915, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-15/pytorch_lora_weights.safetensors\n",
            "Steps:   3% 16/500 [11:34<5:51:35, 43.59s/it, loss=0.223, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-16/pytorch_lora_weights.safetensors\n",
            "Steps:   3% 17/500 [12:18<5:50:40, 43.56s/it, loss=0.00519, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-17/pytorch_lora_weights.safetensors\n",
            "Steps:   4% 18/500 [13:01<5:49:26, 43.50s/it, loss=0.00622, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-18/pytorch_lora_weights.safetensors\n",
            "Steps:   4% 19/500 [13:44<5:48:27, 43.47s/it, loss=0.174, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-19/pytorch_lora_weights.safetensors\n",
            "Steps:   4% 20/500 [14:28<5:47:45, 43.47s/it, loss=0.0411, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-20/pytorch_lora_weights.safetensors\n",
            "Steps:   4% 21/500 [15:12<5:47:46, 43.56s/it, loss=0.0557, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-21/pytorch_lora_weights.safetensors\n",
            "Steps:   4% 22/500 [15:55<5:46:30, 43.49s/it, loss=0.121, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-22/pytorch_lora_weights.safetensors\n",
            "Steps:   4% 22/500 [15:56<5:46:30, 43.49s/it, loss=0.00321, lr=0.0001]\n",
            "Fetching 11 files:   0% 0/11 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "vae_1_0/diffusion_pytorch_model.safetens(â€¦):   0% 0.00/335M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "vae_1_0/diffusion_pytorch_model.safetens(â€¦):  20% 66.4M/335M [00:02<00:09, 27.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "vae_1_0/diffusion_pytorch_model.safetens(â€¦):  40% 133M/335M [00:03<00:05, 36.4MB/s] \u001b[A\u001b[A\n",
            "\n",
            "vae_1_0/diffusion_pytorch_model.safetens(â€¦):  60% 200M/335M [00:05<00:03, 42.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "vae_1_0/diffusion_pytorch_model.safetens(â€¦):  80% 268M/335M [00:06<00:01, 50.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "vae_1_0/diffusion_pytorch_model.safetens(â€¦): 100% 335M/335M [00:07<00:00, 43.3MB/s]\n",
            "\n",
            "Fetching 11 files: 100% 11/11 [00:25<00:00,  2.34s/it]\n",
            "{'image_encoder', 'feature_extractor'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[A{'timestep_type', 'final_sigmas_type', 'use_beta_sigmas', 'use_exponential_sigmas', 'rescale_betas_zero_snr', 'sigma_min', 'sigma_max'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as EulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n",
            "\n",
            "Loading pipeline components...:  29% 2/7 [00:01<00:03,  1.39it/s]\u001b[ALoaded tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n",
            "\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  4.39it/s]\n",
            "{'algorithm_type', 'solver_type', 'final_sigmas_type', 'use_beta_sigmas', 'dynamic_thresholding_ratio', 'use_flow_sigmas', 'euler_at_final', 'time_shift_type', 'use_lu_lambdas', 'use_exponential_sigmas', 'rescale_betas_zero_snr', 'lambda_min_clipped', 'use_dynamic_shifting', 'flow_shift', 'thresholding', 'variance_type', 'lower_order_final', 'solver_order'} was not found in config. Values will be initialized to default values.\n",
            "Steps:   5% 23/500 [39:20<59:53:28, 452.01s/it, loss=0.143, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-23/pytorch_lora_weights.safetensors\n",
            "Steps:   5% 24/500 [40:03<43:33:15, 329.40s/it, loss=0.245, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-24/pytorch_lora_weights.safetensors\n",
            "Steps:   5% 25/500 [40:47<32:08:24, 243.59s/it, loss=0.353, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-25/pytorch_lora_weights.safetensors\n",
            "Steps:   5% 26/500 [41:31<24:11:11, 183.69s/it, loss=0.0525, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-26/pytorch_lora_weights.safetensors\n",
            "Steps:   5% 27/500 [42:14<18:36:56, 141.68s/it, loss=0.208, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-27/pytorch_lora_weights.safetensors\n",
            "Steps:   6% 28/500 [42:58<14:43:22, 112.29s/it, loss=0.00321, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-28/pytorch_lora_weights.safetensors\n",
            "Steps:   6% 29/500 [43:41<11:59:17, 91.63s/it, loss=0.182, lr=0.0001] Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-29/pytorch_lora_weights.safetensors\n",
            "Steps:   6% 30/500 [44:25<10:04:24, 77.16s/it, loss=0.0489, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-30/pytorch_lora_weights.safetensors\n",
            "Steps:   6% 31/500 [45:09<8:45:19, 67.21s/it, loss=0.0225, lr=0.0001] Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-31/pytorch_lora_weights.safetensors\n",
            "Steps:   6% 32/500 [45:52<7:48:52, 60.11s/it, loss=0.00269, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-32/pytorch_lora_weights.safetensors\n",
            "Steps:   7% 33/500 [46:36<7:09:10, 55.14s/it, loss=0.26, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-33/pytorch_lora_weights.safetensors\n",
            "Steps:   7% 34/500 [47:19<6:41:25, 51.68s/it, loss=0.0118, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-34/pytorch_lora_weights.safetensors\n",
            "Steps:   7% 35/500 [48:03<6:21:40, 49.25s/it, loss=0.319, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-35/pytorch_lora_weights.safetensors\n",
            "Steps:   7% 36/500 [48:46<6:07:26, 47.51s/it, loss=0.235, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-36/pytorch_lora_weights.safetensors\n",
            "Steps:   7% 37/500 [49:30<5:57:25, 46.32s/it, loss=0.016, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-37/pytorch_lora_weights.safetensors\n",
            "Steps:   8% 38/500 [50:14<5:50:14, 45.49s/it, loss=0.322, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-38/pytorch_lora_weights.safetensors\n",
            "Steps:   8% 39/500 [50:57<5:45:02, 44.91s/it, loss=0.153, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-39/pytorch_lora_weights.safetensors\n",
            "Steps:   8% 40/500 [51:41<5:40:56, 44.47s/it, loss=0.148, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-40/pytorch_lora_weights.safetensors\n",
            "Steps:   8% 41/500 [52:24<5:38:48, 44.29s/it, loss=0.337, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-41/pytorch_lora_weights.safetensors\n",
            "Steps:   8% 42/500 [53:08<5:36:15, 44.05s/it, loss=0.0547, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-42/pytorch_lora_weights.safetensors\n",
            "Steps:   9% 43/500 [53:52<5:34:44, 43.95s/it, loss=0.011, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-43/pytorch_lora_weights.safetensors\n",
            "Steps:   9% 44/500 [54:35<5:32:56, 43.81s/it, loss=0.0111, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-44/pytorch_lora_weights.safetensors\n",
            "Steps:   9% 45/500 [55:19<5:31:40, 43.74s/it, loss=0.0939, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-45/pytorch_lora_weights.safetensors\n",
            "Steps:   9% 46/500 [56:02<5:30:47, 43.72s/it, loss=0.106, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-46/pytorch_lora_weights.safetensors\n",
            "Steps:   9% 47/500 [56:46<5:29:54, 43.70s/it, loss=0.17, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-47/pytorch_lora_weights.safetensors\n",
            "Steps:  10% 48/500 [57:30<5:29:08, 43.69s/it, loss=0.17, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-48/pytorch_lora_weights.safetensors\n",
            "Steps:  10% 49/500 [58:13<5:28:15, 43.67s/it, loss=0.303, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-49/pytorch_lora_weights.safetensors\n",
            "Steps:  10% 50/500 [58:57<5:27:27, 43.66s/it, loss=0.0686, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-50/pytorch_lora_weights.safetensors\n",
            "Steps:  10% 51/500 [59:41<5:26:38, 43.65s/it, loss=0.0819, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-51/pytorch_lora_weights.safetensors\n",
            "Steps:  10% 52/500 [1:00:24<5:25:37, 43.61s/it, loss=0.301, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-52/pytorch_lora_weights.safetensors\n",
            "Steps:  11% 53/500 [1:01:08<5:25:00, 43.63s/it, loss=0.163, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-53/pytorch_lora_weights.safetensors\n",
            "Steps:  11% 54/500 [1:01:51<5:24:11, 43.61s/it, loss=0.077, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-54/pytorch_lora_weights.safetensors\n",
            "Steps:  11% 55/500 [1:02:35<5:23:19, 43.60s/it, loss=0.298, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-55/pytorch_lora_weights.safetensors\n",
            "Steps:  11% 56/500 [1:03:19<5:23:15, 43.68s/it, loss=0.0655, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-56/pytorch_lora_weights.safetensors\n",
            "Steps:  11% 57/500 [1:04:02<5:22:02, 43.62s/it, loss=0.116, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-57/pytorch_lora_weights.safetensors\n",
            "Steps:  12% 58/500 [1:04:46<5:21:12, 43.60s/it, loss=0.0112, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-58/pytorch_lora_weights.safetensors\n",
            "Steps:  12% 59/500 [1:05:30<5:21:23, 43.73s/it, loss=0.00214, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-59/pytorch_lora_weights.safetensors\n",
            "Steps:  12% 60/500 [1:06:14<5:20:54, 43.76s/it, loss=0.0695, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-60/pytorch_lora_weights.safetensors\n",
            "Steps:  12% 61/500 [1:06:57<5:20:10, 43.76s/it, loss=0.235, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-61/pytorch_lora_weights.safetensors\n",
            "Steps:  12% 62/500 [1:07:41<5:18:54, 43.69s/it, loss=0.164, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-62/pytorch_lora_weights.safetensors\n",
            "Steps:  13% 63/500 [1:08:25<5:18:02, 43.67s/it, loss=0.0456, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-63/pytorch_lora_weights.safetensors\n",
            "Steps:  13% 64/500 [1:09:09<5:18:23, 43.81s/it, loss=0.147, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-64/pytorch_lora_weights.safetensors\n",
            "Steps:  13% 65/500 [1:09:52<5:16:59, 43.72s/it, loss=0.0921, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-65/pytorch_lora_weights.safetensors\n",
            "Steps:  13% 66/500 [1:10:36<5:15:50, 43.67s/it, loss=0.0432, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-66/pytorch_lora_weights.safetensors\n",
            "Steps:  13% 67/500 [1:11:19<5:15:05, 43.66s/it, loss=0.234, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-67/pytorch_lora_weights.safetensors\n",
            "Steps:  14% 68/500 [1:12:03<5:14:13, 43.64s/it, loss=0.0446, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-68/pytorch_lora_weights.safetensors\n",
            "Steps:  14% 69/500 [1:12:47<5:14:01, 43.72s/it, loss=0.21, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-69/pytorch_lora_weights.safetensors\n",
            "Steps:  14% 70/500 [1:13:30<5:13:06, 43.69s/it, loss=0.0178, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-70/pytorch_lora_weights.safetensors\n",
            "Steps:  14% 71/500 [1:14:14<5:11:55, 43.63s/it, loss=0.199, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-71/pytorch_lora_weights.safetensors\n",
            "Steps:  14% 72/500 [1:14:57<5:10:36, 43.54s/it, loss=0.139, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-72/pytorch_lora_weights.safetensors\n",
            "Steps:  15% 73/500 [1:15:41<5:09:36, 43.50s/it, loss=0.303, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-73/pytorch_lora_weights.safetensors\n",
            "Steps:  15% 74/500 [1:16:25<5:10:00, 43.66s/it, loss=0.0602, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-74/pytorch_lora_weights.safetensors\n",
            "Steps:  15% 75/500 [1:17:09<5:09:32, 43.70s/it, loss=0.0606, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-75/pytorch_lora_weights.safetensors\n",
            "Steps:  15% 76/500 [1:17:52<5:08:32, 43.66s/it, loss=0.289, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-76/pytorch_lora_weights.safetensors\n",
            "Steps:  15% 77/500 [1:18:36<5:07:35, 43.63s/it, loss=0.0573, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-77/pytorch_lora_weights.safetensors\n",
            "Steps:  16% 78/500 [1:19:19<5:06:57, 43.64s/it, loss=0.253, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-78/pytorch_lora_weights.safetensors\n",
            "Steps:  16% 79/500 [1:20:03<5:06:39, 43.70s/it, loss=0.0118, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-79/pytorch_lora_weights.safetensors\n",
            "Steps:  16% 80/500 [1:20:47<5:05:46, 43.68s/it, loss=0.186, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-80/pytorch_lora_weights.safetensors\n",
            "Steps:  16% 81/500 [1:21:30<5:04:38, 43.62s/it, loss=0.169, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-81/pytorch_lora_weights.safetensors\n",
            "Steps:  16% 82/500 [1:22:14<5:03:55, 43.63s/it, loss=0.0758, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-82/pytorch_lora_weights.safetensors\n",
            "Steps:  17% 83/500 [1:22:58<5:03:33, 43.68s/it, loss=0.00707, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-83/pytorch_lora_weights.safetensors\n",
            "Steps:  17% 84/500 [1:23:42<5:03:12, 43.73s/it, loss=0.333, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-84/pytorch_lora_weights.safetensors\n",
            "Steps:  17% 85/500 [1:24:25<5:02:10, 43.69s/it, loss=0.0937, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-85/pytorch_lora_weights.safetensors\n",
            "Steps:  17% 86/500 [1:25:09<5:01:16, 43.66s/it, loss=0.00473, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-86/pytorch_lora_weights.safetensors\n",
            "Steps:  17% 87/500 [1:25:52<5:00:26, 43.65s/it, loss=0.0705, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-87/pytorch_lora_weights.safetensors\n",
            "Steps:  18% 88/500 [1:26:36<4:59:43, 43.65s/it, loss=0.00646, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-88/pytorch_lora_weights.safetensors\n",
            "Steps:  18% 89/500 [1:27:20<4:59:30, 43.72s/it, loss=0.00526, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-89/pytorch_lora_weights.safetensors\n",
            "Steps:  18% 90/500 [1:28:04<4:58:54, 43.74s/it, loss=0.162, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-90/pytorch_lora_weights.safetensors\n",
            "Steps:  18% 91/500 [1:28:47<4:57:39, 43.67s/it, loss=0.0225, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-91/pytorch_lora_weights.safetensors\n",
            "Steps:  18% 92/500 [1:29:31<4:56:29, 43.60s/it, loss=0.102, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-92/pytorch_lora_weights.safetensors\n",
            "Steps:  19% 93/500 [1:30:14<4:55:37, 43.58s/it, loss=0.00961, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-93/pytorch_lora_weights.safetensors\n",
            "Steps:  19% 94/500 [1:30:58<4:55:08, 43.62s/it, loss=0.272, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-94/pytorch_lora_weights.safetensors\n",
            "Steps:  19% 95/500 [1:31:41<4:54:16, 43.60s/it, loss=0.121, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-95/pytorch_lora_weights.safetensors\n",
            "Steps:  19% 96/500 [1:32:25<4:53:38, 43.61s/it, loss=0.564, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-96/pytorch_lora_weights.safetensors\n",
            "Steps:  19% 97/500 [1:33:09<4:52:59, 43.62s/it, loss=0.172, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-97/pytorch_lora_weights.safetensors\n",
            "Steps:  20% 98/500 [1:33:52<4:52:12, 43.61s/it, loss=0.00282, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-98/pytorch_lora_weights.safetensors\n",
            "Steps:  20% 99/500 [1:34:36<4:51:29, 43.61s/it, loss=0.0029, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-99/pytorch_lora_weights.safetensors\n",
            "Steps:  20% 100/500 [1:35:20<4:50:46, 43.62s/it, loss=0.259, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-100/pytorch_lora_weights.safetensors\n",
            "Steps:  20% 101/500 [1:36:03<4:50:04, 43.62s/it, loss=0.252, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-101/pytorch_lora_weights.safetensors\n",
            "Steps:  20% 102/500 [1:36:47<4:49:16, 43.61s/it, loss=0.176, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-102/pytorch_lora_weights.safetensors\n",
            "Steps:  21% 103/500 [1:37:30<4:48:22, 43.58s/it, loss=0.265, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-103/pytorch_lora_weights.safetensors\n",
            "Steps:  21% 104/500 [1:38:14<4:48:07, 43.66s/it, loss=0.0207, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-104/pytorch_lora_weights.safetensors\n",
            "Steps:  21% 105/500 [1:38:58<4:48:43, 43.86s/it, loss=0.00602, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-105/pytorch_lora_weights.safetensors\n",
            "Steps:  21% 106/500 [1:39:42<4:47:41, 43.81s/it, loss=0.133, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-106/pytorch_lora_weights.safetensors\n",
            "Steps:  21% 107/500 [1:40:26<4:46:31, 43.75s/it, loss=0.313, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-107/pytorch_lora_weights.safetensors\n",
            "Steps:  22% 108/500 [1:41:09<4:45:33, 43.71s/it, loss=0.158, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-108/pytorch_lora_weights.safetensors\n",
            "Steps:  22% 109/500 [1:41:53<4:44:24, 43.64s/it, loss=0.0278, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-109/pytorch_lora_weights.safetensors\n",
            "Steps:  22% 110/500 [1:42:36<4:43:24, 43.60s/it, loss=0.00379, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-110/pytorch_lora_weights.safetensors\n",
            "Steps:  22% 111/500 [1:43:20<4:42:43, 43.61s/it, loss=0.313, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-111/pytorch_lora_weights.safetensors\n",
            "Steps:  22% 112/500 [1:44:04<4:42:06, 43.62s/it, loss=0.173, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-112/pytorch_lora_weights.safetensors\n",
            "Steps:  23% 113/500 [1:44:47<4:41:10, 43.59s/it, loss=0.1, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-113/pytorch_lora_weights.safetensors\n",
            "Steps:  23% 114/500 [1:45:31<4:40:28, 43.60s/it, loss=0.0853, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-114/pytorch_lora_weights.safetensors\n",
            "Steps:  23% 115/500 [1:46:14<4:39:50, 43.61s/it, loss=0.0363, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-115/pytorch_lora_weights.safetensors\n",
            "Steps:  23% 116/500 [1:46:58<4:39:11, 43.62s/it, loss=0.0031, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-116/pytorch_lora_weights.safetensors\n",
            "Steps:  23% 117/500 [1:47:42<4:38:29, 43.63s/it, loss=0.0542, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-117/pytorch_lora_weights.safetensors\n",
            "Steps:  24% 118/500 [1:48:25<4:37:49, 43.64s/it, loss=0.127, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-118/pytorch_lora_weights.safetensors\n",
            "Steps:  24% 119/500 [1:49:09<4:37:08, 43.64s/it, loss=0.0167, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-119/pytorch_lora_weights.safetensors\n",
            "Steps:  24% 120/500 [1:49:53<4:36:16, 43.62s/it, loss=0.207, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-120/pytorch_lora_weights.safetensors\n",
            "Steps:  24% 121/500 [1:50:36<4:35:41, 43.65s/it, loss=0.29, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-121/pytorch_lora_weights.safetensors\n",
            "Steps:  24% 122/500 [1:51:20<4:34:51, 43.63s/it, loss=0.338, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-122/pytorch_lora_weights.safetensors\n",
            "Steps:  25% 123/500 [1:52:03<4:33:53, 43.59s/it, loss=0.15, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-123/pytorch_lora_weights.safetensors\n",
            "Steps:  25% 124/500 [1:52:47<4:32:48, 43.53s/it, loss=0.0328, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-124/pytorch_lora_weights.safetensors\n",
            "Steps:  25% 125/500 [1:53:30<4:31:50, 43.50s/it, loss=0.288, lr=0.0001]Model weights saved in /content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-125/pytorch_lora_weights.safetensors\n",
            "Steps:  25% 125/500 [1:53:42<4:31:50, 43.50s/it, loss=0.00556, lr=0.0001]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # 5. (Optional) Test your LoRA\n",
        "\n",
        "from huggingface_hub.repocard import RepoCard\n",
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "\n",
        "BASE_MODEL_PATH_OR_ID = \"stabilityai/stable-diffusion-xl-base-1.0\" # @param {type:\"string\"}\n",
        "YOUR_LORA_PATH = \"/content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/something/pytorch_lora_weights.safetensors\" # @param {type:\"string\"}\n",
        "PROMPT = \"photo of a girl's face xxxkatj\" # @param {type:\"string\"}\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(BASE_MODEL_PATH_OR_ID, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.load_lora_weights(YOUR_LORA_PATH)\n",
        "image = pipe(PROMPT, num_inference_steps=25).images[0]\n",
        "image.save(\"sks_dog.png\")\n",
        "\n",
        "from IPython.display import display\n",
        "display(image)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PALmQfvtSk6L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}